{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"extend_the_curve.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOE0apRLDuygHy0Tmqt7GJl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"D1UrIEwpZA4k","colab_type":"text"},"source":["**Purpose**: Provide the functionality of extend_the_curve() as follows:\n","\n","**Inputs**:\n","\n","\n","> y:  *data (dependent variable)*\n","\n","> desired_forecast_periods: *desired number of intervals/periods in forecast*\n","\n","> interval: *constant width on x-axis between adjacent points, which should always be specified whenever same units are used on both axes; interval >= 0; interval == 0 (default) => use average change in y whenever default yields unsatisfactory forecast, try non-zero interval (e.g. interval=1.0)*\n","\n","> origin: *x[0]*\n","\n","> epsilon: *estimate of 'machine' or computational error (normally omit this optional parameter)*\n","\n","\n","> returns: \"step\", \"line\", \"slope\", or \"flag\" as follows\n","\n","> \"step\" *for an integer step-function result*\n","\n","> \"line\" *for the line segment which is the extension of the curve (default)*\n","\n","> \"slope\" *for slope and intercept only \"length\" for for slope and intercept with suggested length of forecast (periods)*\n","\n","> \"flag\" *for slope and intercept with length and flag* \n","\n","Require: 1 < desired_forecast_periods\n","\n","Returns: Depends on return argument, which defaults to \"line\" \n","\n","    \"flag\"\n","        Returns m,i,p,flag\n","            m and i denote the slope and intercept, respectively, of the desired line\n","            p denotes the number of valid periods for forecast\n","            flag  < 1 indicates forecast is proportionately less reliable for desired period, \n","            flag >= 1 indicates forecast if proportionately more reliable for desired period\n","\n","    \"length\"\n","        Returns m,i\n","            m and i denote the slope and intercept, respectively, of the desired line, and\n","            suggested number of periods in forecast, which is the suggested length of the predicted line\n","\n","    \"slope\"\n","        Returns m,i\n","            m and i denote the slope and intercept, respectively, of the desired line\n","\n","    \"step\"\n","        Returns z\n","            z is the extended line segment or step-function rounding results to integers\n","\n","    \"line\"\n","        Returns z\n","            z is the extended line segment\n","\n","(C) COPYRIGHT NOTICE\n","\n","All or portions of the documentation and software included in this software\n","distribution from AFLCMC/HNII are copyrighted by Stephen Bique, who has assigned\n","All Rights for those portions to AFLCMC/HNII.  Outside the USA, AFLCMC/HNII has\n","copyright on some or all of the software developed for AFLCMC/HNII. Any files may\n","contain specific copyright notices and those notices must be retained in any derived\n","work.\n","\n","AFLCMC/HNII LICENSE\n","\n","AFLCMC/HNII may grant permission for redistribution and use in source and binary\n","forms, with or without modification, of this software and documentation\n","created for AFLCMC/HNII provided that the following conditions are met:\n","\n","1. Redistributions of source code must retain the above copyright\n","   notice, this list of conditions and the following disclaimer.\n","2. Redistributions in binary form must reproduce the above copyright\n","   notice, this list of conditions and the following disclaimer in the\n","   documentation and/or other materials provided with the distribution.\n","3. All advertising materials mentioning features or use of this software\n","   must display the following acknowledgements:\n","\n","   This product includes software developed for AFLCMC/HNII.\n","\n","4. Neither the name of AFLCMC/HNII nor the names of its contributors\n","   may be used to endorse or promote products derived from this software\n","   without specific prior written permission.\n","\n","THE SOFTWARE PROVIDED BY AFLCMC/HNII IS PROVIDED BY AFLCMC/HNII AND CONTRIBUTORS\n","``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n","TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n","PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL AFLCMC/HNII OR\n","CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n","EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n","PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n","PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n","LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n","NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n","SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n","\n","The views and conclusions contained in the software and documentation\n","are those of the authors and should not be interpreted as representing\n","official policies, either expressed or implied, of AFLCMC/HNII.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ufeihmQogndx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596126525706,"user_tz":300,"elapsed":1199,"user":{"displayName":"Stephen Bique","photoUrl":"","userId":"10036147318147259626"}}},"source":["def extend_the_curve(y, desired_forecast_periods=14, interval=0.0, origin=0.0, returns=\"line\", epsilon = 0.0000005):\n","  import numpy as np\n","  from sklearn.linear_model import LinearRegression\n","  from scipy import stats\n","  import re\n","\n","  y = np.asarray(y)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-cSov7or_Fu","colab_type":"text"},"source":["     Seek a method that in some sense is not too sensitive to slight changes in the data.\n","     So we seek to obtain mostly consistent answers with slightly perturbed data.\n","\n","     As we look larger and larger samples, we expect the variance to become less,\n","     approaching the variance of the noise that is added. However, there is an inherent\n","     problem: for the smaller samples, we expect higher variance, which makes a fair\n","     comparison more difficult."]},{"cell_type":"markdown","metadata":{"id":"VEmzUzA6sZF2","colab_type":"text"},"source":["Get average change in y:"]},{"cell_type":"code","metadata":{"id":"C9UplQ_Rs2zY","colab_type":"code","colab":{}},"source":["  scale = np.average([abs(v - y[j]) for j, v in enumerate(y[1:])])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hWzXFQRs_YE","colab_type":"text"},"source":["Check interval width and set if invalid"]},{"cell_type":"code","metadata":{"id":"5n0rPE4GtFii","colab_type":"code","colab":{}},"source":["  if interval <= epsilon:\n","    interval = scale # use average change in y\n","    if interval <= epsilon:\n","      interval = 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Px-SpZOHtcaT","colab_type":"text"},"source":["Define x"]},{"cell_type":"code","metadata":{"id":"_8KPB2nwtezD","colab_type":"code","colab":{}},"source":["  x = np.asarray([j * interval + origin for j in range(len(y))])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee7p81X8tlZO","colab_type":"text"},"source":["Set reasonable scale for noise to perturb values of y:"]},{"cell_type":"code","metadata":{"id":"0Y7h1yEDtpsV","colab_type":"code","colab":{}},"source":["  scale = max(0.00015, scale * 0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Mtvio_TtuQb","colab_type":"text"},"source":["\n","    Unless change in recent data indicates possibly zero slope, start with six points; otherwise, four points.\n","    Assuming errors in the data, the recent slopes may be invalid. Before we suspect zero slope, we expect\n","    either the slope is constant (no change in the data) or slopes are approaching zero.\n","    If the angles in degrees decrease approximately from 47 to 32 to 15, we conservatively guess slope might\n","    be tending to zero."]},{"cell_type":"code","metadata":{"id":"Y5ngXTz3twCF","colab_type":"code","colab":{}},"source":["  slope0 = abs(y[-3] - y[-4]) / interval\n","  slope1 = abs(y[-2] - y[-3]) / interval\n","  slope2 = abs(y[-1] - y[-2]) / interval\n","\n","  if (slope0 < 1.07237) and (slope1 < 0.62487) and (slope2 < 0.26795):\n","    start = 4\n","  else:\n","    start = 6\n","\n","  while True:\n","    hs = []\n","    for _ in range(373):\n","      # round\n","\n","      # Fix perturbed y for this round\n","      y_noisy = y + np.random.normal(0.0, scale, size=len(y))\n","\n","      # Initializations\n","      first_time = True\n","      rmse0 = 0.0\n","      h_best = max(6, desired_forecast_periods)\n","      size = h_best - start + 1\n","      h = start - 1\n","      for _ in range(size):\n","        h1 = h\n","        h = h1 + 1\n","\n","            first = len(x) - h1  # use points first..last, inv. fixed on ea. loop execution\n","\n","            X = x[first:]\n","            Y = y_noisy[first:]\n","\n","            slope, intercept, r_value, p_value, std_err = stats.linregress(X, Y)\n","\n","            rmse = sum([abs(slope * X[j] + intercept - val) for j, val in enumerate(Y)]) / float(len(X))\n","\n","            if first_time:\n","              rmse0 = rmse\n","              if rmse < epsilon:\n","                f = 0.255\n","              else:\n","                f = rmse * 0.255\n","              first_time = False\n","            elif rmse - rmse0 > f:\n","\n","              h_best = h - 1\n","              break\n","\n","            hs.append(h_best)\n","\n","    # Count frequencies of mode and next most frequently occurring value, possibly the same frequency\n","    freq = {}  # Creating an empty dictionary\n","    for item in hs:\n","      if (item in freq):\n","        freq[item] += 1\n","      else:\n","        freq[item] = 1\n","    f1 = 0\n","    f2 = 0\n","    for key, value in freq.items():\n","      if value >= f1:\n","        f2 = f1\n","        f1 = value\n","        m = key\n","      elif value >= f2:\n","        f2 = value\n","      if (f1 - f2 > 22):\n","\n","        # Determine weights for linear regression\n","        m1 = m + 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TKyvdPw5v4OJ","colab_type":"text"},"source":["            Suppose there is a small absolute error in m.\n","            If m is fairly large, then such small error is likely\n","            not nearly as 'bad' as when m is small.\n","            When m is small, there is a good chance that\n","            the best m is actually smaller. Why? Because whenever\n","            there is a maxima or minima, the best regression line\n","            minimizes the computed error but deviates from the tangent.\n","            In particular, if the curve is leveling off, the above algorithm\n","            will likely find m=4 as that is the smallest possible.\n","            When m is large, it is likely the error will be small\n","            if a smaller value is used.\n","            With the above justification, we normally give more\n","            weight to points closer to the last observation.\n","            However, if the function behaves like a step-function,\n","            or if there are significant changes in the slope, then we\n","            conservatively apply equal weights to all points."]},{"cell_type":"code","metadata":{"id":"lGhB4tAhwKUU","colab_type":"code","colab":{}},"source":["        changes = 0\n","        last = y[-m1]\n","        last_change = y[-m] - last\n","        if abs(last_change) < epsilon:\n","          no_times_constant = 1\n","        else:\n","          no_times_constant = 0\n","        for value in y[-m + 1:]:\n","          change = value - last\n","          if ((last_change >= 0) != (change >= 0)):\n","            changes += 1\n","            last_change = change\n","          if abs(change) < epsilon:\n","            no_times_constant += 1\n","          last = value\n","\n","        # Does the function behave partly as a step-function?\n","        if no_times_constant >= max(1, m * 0.2):\n","          # If the function is a step-function, our regression approach\n","          # may have underestimated m.\n","          m_ext = desired_forecast_periods - m\n","          if m < desired_forecast_periods:\n","            last = y[-desired_forecast_periods]\n","            no_times = 0\n","            for value in y[-desired_forecast_periods+1:-m]:\n","              if abs(value - last) < epsilon:\n","                no_times += 1\n","              last = value\n","            if no_times >= max(1, m_ext * 0.2):\n","              m = desired_forecast_periods # adjust m\n","\n","          use_adj_weights = False\n","\n","        elif (m <= 4):"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"posKUM95xdU_","colab_type":"text"},"source":["                  Consider   'actual' m      predicted m   'effectve' m using assigned weights\n","                                 1               4                      2\n","                                 2               4                      2  \n","                                 3               4                      2\n","                                 4               4                      2\n","                  If we suppose that m's in the range 1-4 are more likely < 4, then by using the 'effective' m's,\n","                  we will be assigning better weights in view of the 'actual' m's. The supposition is reasonable \n","                  since there is no reason to claim the m's are not approximately uniformly distributed."]},{"cell_type":"code","metadata":{"id":"C5DQjKfbxpOT","colab_type":"code","colab":{}},"source":["          use_adj_weights = True  # linearly adjust keeping sum of weights equal to m\n","        elif changes >= max(1, m * 0.125) or m < max(14, desired_forecast_periods):\n","          # The function's slope changes sign significantly, or\n","          # m is small enough that the recent points are weighed sufficiently heavily.\n","          use_adj_weights = False\n","        else:\n","          use_adj_weights = True # linearly adjust keeping sum of weights equal to m\n","\n","          w = [1.0] * m   # start with uniform weights\n","          first = len(x) - m\n","\n","          X = x[first:]\n","          Y = y[first:]\n","\n","          # sckit-learn implementation\n","          # Use only one feature\n","          u = X.reshape(-1, 1)\n","          v = Y.reshape(-1, 1)\n","\n","          # Model fit\n","          regression_model = LinearRegression().fit(u, v, w)\n","          slope = regression_model.coef_[0][0]\n","\n","          # Adjust line to go through last point\n","          intercept = Y[-1] - slope * X[-1]\n","\n","          if use_adj_weights:\n","            R0 = [pow(x * slope + intercept - y, 2) for x, y in zip(X,Y)]\n","            a = 0.0  # left bound for weight factor\n","            b = 1.0  # right bound for weight factor\n","\n","            # Assign weights with higher values for points closer to the rightmost observation\n","            wsum = 2.0 / float(m1)\n","            w1 = np.asarray([v * wsum for v in range(1, m1, 1)])\n","            w0 = np.asarray([1.0] * m)\n","\n","            # Apply bisection algorithm to search for best weight factor to linearly combine w0 & w1\n","            while (b-a) >= 0.01:\n","              fact = (a + b) / 2\n","\n","              wc = 1.0 - fact\n","              w = w1 * fact + w0 * wc\n","\n","              # Model fit\n","              regression_model = LinearRegression().fit(u, v, w)\n","              slope_ = regression_model.coef_[0][0]\n","\n","              # Adjust line to go through last point\n","              intercept_ = Y[-1] - slope * X[-1]\n","\n","              R = [pow(x * slope_ + intercept_ - y, 2) for x, y in zip(X, Y)]\n","              if R < R0:\n","                R0 = R\n","                slope = slope_\n","                intercept = intercept_\n","                a = fact\n","              else:\n","                b = fact\n","\n","        returns = re.sub(r'[^a-z\\d ]','',returns.lower())\n","        if (\"length\" in returns) or (\"flag\" in returns):\n","          # Return additional values (m and flag), mainly for testing purposes.\n","          # To ignore extra values, use slope,intercept,_,_ = extend_the_curve(y)\n","\n","          # Check m by recalculating using given data and computed line\n","          rsum = 0.0\n","          for j in [-4, -3, -2, -1]:\n","            rsum += abs(slope * x[j] + intercept - y[j])\n","          m_best = 4\n","          eps = epsilon * 4.0\n","          rbest = rsum / 4.0\n","          m_max = min(desired_forecast_periods * 2 + 3, len(x))\n","          for j in range(-5, -m_max, -1):\n","            rsum += abs(slope * x[j] + intercept - y[j])\n","            r = rsum / float(-j)\n","            eps += epsilon\n","            if r <= rbest + epsilon:\n","              m_best = -j\n","\n","          if m < m_best:\n","            m = m_best\n","          if \"flag\" in returns:\n","            return (slope, intercept, m, m / desired_forecast_periods)\n","          else:\n","            return (slope, intercept, m)\n","\n","        elif \"slope\" in returns:\n","          # Alternatively, just return slope and intercept:\n","          return (slope, intercept)\n","        else:\n","          # Alternatively, return predicted line segment:\n","          val = x[-1]\n","          result = []\n","          if \"step\" in returns:\n","            for index in range(desired_forecast_periods):\n","              val += interval\n","              result.append(round(slope * val + intercept))\n","          else:\n","            for index in range(desired_forecast_periods):\n","              val += interval\n","              result.append(slope * val + intercept)\n","          return result"],"execution_count":null,"outputs":[]}]}